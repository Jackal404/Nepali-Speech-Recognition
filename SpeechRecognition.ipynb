{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9206,
     "status": "ok",
     "timestamp": 1582642311951,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "ase7ZVE8OtRp",
    "outputId": "49af2be5-7be1-464d-f2ff-06e994ade7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=ec4b5be9032977dec6683bac8a4c1803636cbf6b95739336142eddd78c7aacc3\n",
      "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30979,
     "status": "ok",
     "timestamp": 1582642346907,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "ZAsr5cHe91HM",
    "outputId": "3e2a136e-66cd-4461-b46e-949c8944434a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5280,
     "status": "ok",
     "timestamp": 1582642424967,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "-JgUC3KZOqK6",
    "outputId": "7533197b-9fb5-4929-92f7-ab2b5abc2ee7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "from tensorflow.python import ops\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1865,
     "status": "ok",
     "timestamp": 1582642436220,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "_20gT2H5OqLO",
    "outputId": "0a9fbdac-7208-40ec-d835-c6bf4c1e0f33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"अआइईउऊएऐओऔअंअ:ककाकिकीकुकूकेकैकोकौकंक:खखाखिखीखुखूखेखैखोखौखंख:गगागिगीगुगूगेगैगोगौगंग:घघाघिघीघुघूघेघैघोघौघंघ:ङङाङिङीङुङूङेङैङोङौङंङ:चचाचिचीचुचूचेचैचोचौचंच:छछाछिछीछुछूछेछैछोछौछंछ:जजाजिजीजुजूजेजैजोजौजंज:झझाझिझीझुझूझेझैझोझौझंझ:ञञाञिञीञुञूञेञैञोञौञंञ:टटाटिटीटुटूटेटैटोटौटंट:ठठाठिठीठुठूठेठैठोठौठंठ:डडाडिडीडुडूडेडैडोडौडंड:ढढाढिढीढुढूढेढैढोढौढंढ:णणाणिणीणुणूणेणैणोणौणंण:ततातितीतुतूतेतैतोतौतंत:थथाथिथीथुथूथेथैथोथौथंथ:ददादिदीदुदूदेदैदोदौदंद:धधाधिधीधुधूधेधैधोधौधंध:ननानिनीनुनूनेनैनोनौनंन:पपापिपीपुपूपेपैपोपौपंप:फफाफिफीफुफूफेफैफोफौफंफ:बबाबिबीबुबूबेबैबोबौबंब:भभाभिभीभुभूभेभैभोभौभंभ:ममामिमीमुमूमेमैमोमौमंम:ययायियीयुयूयेयैयोयौयंय:ररारिरीरुरूरेरैरोरौरंर:ललालिलीलुलूलेलैलोलौलंल:ववाविवीवुवूवेवैवोवौवंव:शशाशिशीशुशूशेशैशोशौशंश:षषाषिषीषुषूषेषैषोषौषंष:ससासिसीसुसूसेसैसोसौसंस:हहाहिहीहुहूहेहैहोहौहंह:क्षक्षाक्षिक्षीक्षुक्षूक्षेक्षैक्षोक्षौक्षंक्ष:त्रत्रात्रित्रीत्रुत्रूत्रेत्रैत्रोत्रौत्रंत्र:ज्ञज्ञाज्ञिज्ञीज्ञुज्ञूज्ञेज्ञैज्ञोज्ञौज्ञंज्ञ:' \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = \"अ, आ, इ, ई, उ, ऊ, ए, ऐ, ओ, औ, अं, अ:, क, का, कि, की, कु, कू, के, कै, को, कौ, कं, क:, ख, खा, खि, खी, खु, खू, खे, खै, खो, खौ, खं, ख:, ग, गा, गि, गी, गु, गू, गे, गै, गो, गौ, गं, ग:, घ ,घा, घि, घी, घु, घू, घे, घै, घो, घौ, घं, घ: ङ, ङा, ङि, ङी, ङु, ङू, ङे, ङै, ङो, ङौ, ङं, ङ:, च, चा, चि, ची, चु, चू, चे, चै, चो, चौ, चं, च:, छ, छा, छि, छी, छु, छू, छे, छै, छो, छौ, छं, छ: ज, जा, जि, जी, जु, जू, जे, जै, जो, जौ, जं, ज: झ, झा, झि, झी, झु, झू, झे, झै, झो, झौ, झं, झ:, ञ, ञा, ञि, ञी, ञु, ञू, ञे, ञै, ञो, ञौ, ञं, ञ:, ट, टा, टि, टी, टु, टू, टे, टै, टो, टौ, टं, ट:, ठ, ठा, ठि, ठी, ठु, ठू, ठे, ठै, ठो, ठौ, ठं, ठ:, ड, डा, डि, डी, डु, डू, डे, डै, डो, डौ, डं, ड:, ढ, ढा, ढि, ढी, ढु, ढू, ढे, ढै, ढो, ढौ, ढं, ढ:, ण, णा, णि, णी, णु, णू, णे, णै, णो, णौ, णं, ण:, त, ता, ति, ती, तु, तू, ते, तै, तो, तौ, तं, त:, थ, था, थि, थी, थु, थू, थे, थै, थो, थौ, थं, थ:, द, दा, दि, दी, दु, दू, दे, दै, दो, दौ, दं, द:, ध, धा, धि, धी, धु, धू, धे, धै, धो, धौ, धं, ध:, न, ना, नि, नी, नु, नू, ने, नै, नो, नौ, नं, न:, प, पा, पि, पी, पु, पू, पे, पै, पो, पौ, पं, प:, फ, फा, फि, फी, फु, फू, फे, फै, फो, फौ, फं, फ:, ब, बा, बि, बी, बु, बू, बे, बै, बो, बौ, बं, ब:, भ, भा, भि, भी, भु, भू, भे, भै, भो, भौ, भं, भ:, म, मा, मि, मी, मु, मू, मे, मै, मो, मौ, मं, म:, य, या, यि, यी, यु, यू, ये, यै, यो, यौ, यं, य:, र, रा, रि, री, रु, रू, रे, रै, रो, रौ, रं, र:, ल, ला, लि, ली, लु, लू, ले, लै, लो, लौ, लं, ल:, व, वा, वि, वी, वु, वू, वे, वै, वो, वौ, वं, व:, श, शा, शि, शी, शु, शू, शे, शै, शो, शौ, शं, श:, ष, षा, षि, षी, षु, षू, षे, षै, षो, षौ, षं, ष:, स, सा, सि, सी, सु, सू, से, सै, सो, सौ, सं, स:, ह, हा, हि, ही, हु, हू, हे, है, हो, हौ, हं, ह:, क्ष, क्षा, क्षि, क्षी, क्षु, क्षू, क्षे, क्षै, क्षो, क्षौ, क्षं, क्ष:, त्र, त्रा, त्रि, त्री, त्रु, त्रू, त्रे, त्रै, त्रो, त्रौ, त्रं, त्र:, ज्ञ, ज्ञा, ज्ञि, ज्ञी, ज्ञु, ज्ञू, ज्ञे, ज्ञै, ज्ञो, ज्ञौ, ज्ञं, ज्ञ:,' \" #type all nepali letters for labelling eg: a,aa,i,e,u,uu,ae,ai,o,au,am ah.........\n",
    "chars = chars.replace(',','')\n",
    "chars= chars.replace(\" \",\"\")\n",
    "chars = chars +\" \"\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWszZT5KOqLI"
   },
   "outputs": [],
   "source": [
    "n_inp=26\n",
    "n_ctx = 9\n",
    "n_h = 1024\n",
    "n_chars = len(chars)+1\n",
    "pb1 = 0.9\n",
    "pb2 = 0.999\n",
    "peps = 1e-8\n",
    "plr = 0.001\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxjQseRNOqLV"
   },
   "outputs": [],
   "source": [
    "def audiofile_to_vector(audio_fname, n_mfcc_features, nctx):\n",
    "    sampling_rate, raw_w = wavfile.read(audio_fname)\n",
    "    mfcc_ft = mfcc(raw_w, samplerate=sampling_rate, numcep=n_mfcc_features)\n",
    "    mfcc_ft = mfcc_ft[::2]\n",
    "    n_strides = len(mfcc_ft)\n",
    "    dummy_ctx = np.zeros((nctx, n_mfcc_features), dtype=mfcc_ft.dtype)\n",
    "    mfcc_ft = np.concatenate((dummy_ctx, mfcc_ft, dummy_ctx))\n",
    "    w_size = 2*nctx+1\n",
    "    input_vector = np.lib.stride_tricks.as_strided(mfcc_ft,(n_strides, w_size, n_mfcc_features),\n",
    "        (mfcc_ft.strides[0], mfcc_ft.strides[0], mfcc_ft.strides[1]),\n",
    "        writeable=False)\n",
    "    input_vector = np.reshape(input_vector, [n_strides, -1])\n",
    "    input_vector = np.copy(input_vector)\n",
    "    input_vector = (input_vector - np.mean(input_vector))/np.std(input_vector)\n",
    "    return input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2004,
     "status": "ok",
     "timestamp": 1582642446338,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "Cd3sOWddOqLb",
    "outputId": "69193fcd-ed38-4de3-ff0f-cfea11f2418e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 494)\n"
     ]
    }
   ],
   "source": [
    "mfcc_features = audiofile_to_vector('./train_data/nep_0258_0119737288.wav',26,9)\n",
    "print(mfcc_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4auxeD8pOqLh"
   },
   "outputs": [],
   "source": [
    "#regexp_alphabets = \"[^a-zA-Z']+\"\n",
    "cnt=0\n",
    "def get_label(ch):\n",
    "    global cnt\n",
    "    label = cnt\n",
    "    cnt+=1\n",
    "    return label\n",
    "chr2lbl = {c:get_label(c) for c in list(chars)}\n",
    "lbl2chr = {chr2lbl[c]:c for c in list(chars)}\n",
    "def get_string2label(strval):\n",
    "    #strval = strval.lower()\n",
    "    idlist = []\n",
    "    for c in list(strval):\n",
    "        if c in chr2lbl:\n",
    "            idlist.append(chr2lbl[c])\n",
    "    return np.array(idlist)\n",
    "def get_label2string(lblarr):\n",
    "    strval = []\n",
    "    for idv in lblarr:\n",
    "        strval.append(lbl2chr[idv])\n",
    "    return ''.join(strval)\n",
    "def decoded_val_to_text(decoded_val):\n",
    "    idxs = decoded_val[0]\n",
    "    vals = decoded_val[1]\n",
    "    res = [''] * decoded_val[2][0]\n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i][0]\n",
    "        char = lbl2chr[vals[i]]\n",
    "        res[idx] = res[idx] + char\n",
    "    return res\n",
    "def array2txt(arr_val):\n",
    "    res = ''\n",
    "    for i in range(len(arr_val)):\n",
    "        if arr_val[i] in lbl2chr:\n",
    "            res += lbl2chr[arr_val[i]]\n",
    "        else:\n",
    "            res += ''\n",
    "    return res.replace('`', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1582642452849,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "qYrLGzClOqLo",
    "outputId": "53513ecb-e047-4bcd-fac8-f316f2ae3c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[587 893 865 901 915 472 873 587 915   1 702 877 818 915 816 893 748 881\n",
      " 915 771 901]\n",
      "मेरो नाम आशिष केसी हो\n"
     ]
    }
   ],
   "source": [
    "idlist = get_string2label(\"मेरो नाम आशिष केसी हो\")\n",
    "print(idlist)\n",
    "strval = get_label2string(idlist)\n",
    "print(strval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7aetB5iOqLw"
   },
   "outputs": [],
   "source": [
    "def get_wav_trans(fpath,X, y):\n",
    "    files = os.listdir(fpath)\n",
    "    for fname in files:\n",
    "        next_path = fpath + \"/\" + fname\n",
    "        if os.path.isdir(next_path):\n",
    "            get_wav_trans(next_path,X,y)\n",
    "        else:\n",
    "            if fname.endswith('wav'):\n",
    "                fname_without_ext = fname.split(\".\")[0]\n",
    "                trans_fname = fname_without_ext + \".txt\"\n",
    "                trans_fname_path = fpath + \"/\" + trans_fname\n",
    "                if os.path.isfile(trans_fname_path):\n",
    "                    mfcc_ft = audiofile_to_vector(next_path,n_inp,n_ctx)\n",
    "                    with open(trans_fname_path,'r') as content:\n",
    "                        transcript = content.read()\n",
    "                        transcript = re.sub(regexp_alphabets, ' ', transcript).strip().lower()\n",
    "                    trans_lbl = get_string2label(transcript)\n",
    "                    X.append(mfcc_ft)\n",
    "                    y.append(trans_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0i_4rQuOqL1"
   },
   "outputs": [],
   "source": [
    "def get_layers(X_batch,seq_len):\n",
    "    X_batch_shape = tf.shape(X_batch)\n",
    "    X_batch = tf.transpose(X_batch, [1, 0, 2])\n",
    "    X_batch = tf.reshape(X_batch, [-1, n_inp + 2*n_inp*n_ctx])\n",
    "    \n",
    "    with tf.name_scope('Lyr1'):\n",
    "        B1 = tf.get_variable(name='B1', shape=[n_h], \n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        H1 = tf.get_variable(name='H1', shape=[n_inp + 2*n_inp*n_ctx, n_h],\n",
    "                             initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "        logits1 = tf.add(tf.matmul(X_batch, H1), B1)\n",
    "        relu1 = tf.nn.relu(logits1)\n",
    "        clipped_relu1 = tf.minimum(relu1,20.0)\n",
    "        Lyr1 = tf.nn.dropout(clipped_relu1, 0.5)\n",
    "    with tf.name_scope('Lyr2'):\n",
    "        B2 = tf.get_variable(name='B2', shape=[n_h], \n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        H2 = tf.get_variable(name='H2', shape=[n_h,n_h],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        logits2 = tf.add(tf.matmul(Lyr1, H2), B2)\n",
    "        relu2 = tf.nn.relu(logits2)\n",
    "        clipped_relu2 = tf.minimum(relu2,20.0)\n",
    "        Lyr2 = tf.nn.dropout(clipped_relu2, 0.5)\n",
    "    with tf.name_scope('Lyr3'):\n",
    "        B3 = tf.get_variable(name='B3', shape=[2*n_h], \n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        H3 = tf.get_variable(name='H3', shape=[n_h,2*n_h],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        logits3 = tf.add(tf.matmul(Lyr2, H3), B3)\n",
    "        relu3 = tf.nn.relu(logits3)\n",
    "        clipped_relu3 = tf.minimum(relu3,20.0)\n",
    "        Lyr3 = tf.nn.dropout(clipped_relu3, 0.5)\n",
    "    \n",
    "    with tf.name_scope('RNN_Lyr'):\n",
    "        fw_c = tf.contrib.rnn.BasicLSTMCell(n_h, forget_bias=1.0, state_is_tuple=True, \n",
    "                                            reuse=tf.get_variable_scope().reuse)\n",
    "        fw_c = tf.contrib.rnn.DropoutWrapper(fw_c, input_keep_prob=0.7, output_keep_prob=0.7,seed=123)\n",
    "        bw_c = tf.contrib.rnn.BasicLSTMCell(n_h, forget_bias=1.0, state_is_tuple=True, \n",
    "                                                    reuse=tf.get_variable_scope().reuse)\n",
    "        bw_c = tf.contrib.rnn.DropoutWrapper(bw_c,input_keep_prob=0.7, output_keep_prob=0.7,\n",
    "                                                    seed=123)\n",
    "        Lyr3 = tf.reshape(Lyr3, [-1, X_batch_shape[0], 2*n_h])\n",
    "        outs, out_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_c,\n",
    "                                                                     cell_bw=bw_c,\n",
    "                                                                     inputs=Lyr3,\n",
    "                                                                     dtype=tf.float32,\n",
    "                                                                     time_major=True,\n",
    "                                                                     sequence_length=seq_len)\n",
    "        outs = tf.concat(outs, 2)\n",
    "        outs = tf.reshape(outs, [-1, 2 * n_h])\n",
    "    \n",
    "    with tf.name_scope('Lyr4'):\n",
    "        B4 = tf.get_variable(name='B4', shape=[n_h], \n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        H4 = tf.get_variable(name='H4', shape=[(2 * n_h), n_h],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        logits4 = tf.add(tf.matmul(outs, H4), B4)\n",
    "        relu4 = tf.nn.relu(logits4)\n",
    "        clipped_relu4 = tf.minimum(relu4,20.0)\n",
    "        Lyr4 = tf.nn.dropout(clipped_relu4, 0.5)\n",
    "    \n",
    "    with tf.name_scope('Lyr5'):\n",
    "        B5 = tf.get_variable(name='B5', shape=[n_chars], \n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        H5 = tf.get_variable(name='H5', shape=[n_h, n_chars],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.046875))\n",
    "        Lyr5 = tf.add(tf.matmul(Lyr4, H5), B5)\n",
    "        Lyr5 = tf.reshape(Lyr5, [-1, X_batch_shape[0], n_chars])\n",
    "    \n",
    "    return Lyr5\n",
    "    \n",
    "\n",
    "def get_logits(X_batch,seq_len):\n",
    "    logits = get_layers(X_batch,seq_len)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTo4P_DrOqL6"
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self):\n",
    "        self.start_idx = 0\n",
    "        self.batch_size = 32\n",
    "        self.audio = []\n",
    "        self.transcript = []\n",
    "        get_wav_trans(\"./train_data\",self.audio,self.transcript)     \n",
    "    def pad_seq(self,seqs):\n",
    "        seq_lens = np.asarray([len(st) for st in seqs], dtype=np.int64)\n",
    "        n_s = len(seqs)\n",
    "        max_seq_len = np.max(seq_lens)\n",
    "        s_shape = tuple()\n",
    "        for s in seqs:\n",
    "            if len(s) > 0:\n",
    "                s_shape = np.asarray(s).shape[1:]\n",
    "                break\n",
    "        seqs_trc = (np.ones((n_s, max_seq_len) + s_shape) * 0.).astype(np.float32)\n",
    "        for ix, s in enumerate(seqs):\n",
    "            if len(s) == 0:\n",
    "                continue  \n",
    "            trc = s[:max_seq_len]\n",
    "            trc = np.asarray(trc, dtype=np.int64)\n",
    "            if trc.shape[1:] != s_shape:\n",
    "                raise ValueError(\"ERROR in truncation shape\")\n",
    "            seqs_trc[ix, :len(trc)] = trc\n",
    "        return seqs_trc, seq_lens\n",
    "    def get_sp_tuple(self,seqs):\n",
    "        ixs = []\n",
    "        vals = []\n",
    "        for n, s in enumerate(seqs):\n",
    "            ixs.extend(zip([n] * len(s), range(len(s))))\n",
    "            vals.extend(s)\n",
    "        ixs = np.asarray(ixs, dtype=np.int64)\n",
    "        vals = np.asarray(vals, dtype=np.int32)\n",
    "        shape = np.asarray([len(seqs), ixs.max(0)[1] + 1], dtype=np.int64)\n",
    "        return ixs, vals, shape\n",
    "    def get_next_batch(self):\n",
    "        src = self.audio[self.start_idx:self.start_idx+self.batch_size]\n",
    "        tgt = self.transcript[self.start_idx:self.start_idx+self.batch_size]\n",
    "        self.start_idx += self.batch_size\n",
    "        if(self.start_idx>len(self.audio)):\n",
    "            self.start_idx=0\n",
    "        src,src_len = self.pad_seq(src)\n",
    "        sp_lbls = self.get_sp_tuple(tgt)\n",
    "        return src, src_len, sp_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDpwTUxgOqMC"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_t = tf.placeholder(tf.float32, [None, None, n_inp + \n",
    "                                                (2 * n_inp * n_ctx)], name='inp')\n",
    "    tgts = tf.sparse_placeholder(tf.int32, name='tgts')\n",
    "    len_seq = tf.placeholder(tf.int32, [None], name='len_seq')\n",
    "    logits = get_logits(input_t,tf.to_int64(len_seq))\n",
    "    return input_t, tgts, len_seq, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cku_BwOJOqMH"
   },
   "outputs": [],
   "source": [
    "def get_cost(tgts,logits,len_seq):\n",
    "    loss_t = ops.ctc_ops.ctc_loss(tgts, logits, len_seq)\n",
    "    loss_avg = tf.reduce_mean(loss_t)\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GQedttrOqMN"
   },
   "outputs": [],
   "source": [
    "def get_optimizer(logits,len_seq,loss_avg):\n",
    "    adm_opt = tf.train.AdamOptimizer(learning_rate=plr,beta1=pb1,beta2=pb2,epsilon=peps)\n",
    "    adm_opt = adm_opt.minimize(loss_avg)\n",
    "    dec, prob_log = ops.ctc_ops.ctc_beam_search_decoder(logits, len_seq, merge_repeated=False)\n",
    "    return adm_opt,dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXoYYPoJOqMS"
   },
   "outputs": [],
   "source": [
    "def get_error_rates(dec,tgts):\n",
    "    edit_dist = tf.edit_distance(tf.cast(dec[0], tf.int32), tgts)\n",
    "    error_rate4label = tf.reduce_mean(edit_dist, name='error_rate4label')\n",
    "    return error_rate4label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1441
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3913,
     "status": "error",
     "timestamp": 1582642482926,
     "user": {
      "displayName": "Ashish K.C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAOuw0bC02Je33dbX8-4OaGJX48BiEADQSQF7xy8A=s64",
      "userId": "08434534104772020675"
     },
     "user_tz": -345
    },
    "id": "I32SYwh7OqMX",
    "outputId": "4ae957f3-5264-4ff8-a182-3df59e436089",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1a495ab1c944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0madm_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_avg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-281b18dc8f6a>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     input_t = tf.placeholder(tf.float32, [None, None, n_inp + \n\u001b[0m\u001b[0;32m      3\u001b[0m                                                 (2 * n_inp * n_ctx)], name='inp')\n\u001b[0;32m      4\u001b[0m     \u001b[0mtgts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tgts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlen_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'len_seq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "gr = tf.Graph()\n",
    "with gr.as_default():\n",
    "    input_t,tgts,len_seq,logits = get_model()\n",
    "    loss_avg = get_cost(tgts,logits,len_seq)\n",
    "    adm_opt, dec = get_optimizer(logits,len_seq,loss_avg)\n",
    "    error_rate = get_error_rates(dec,tgts)\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter('./', graph=sess.graph)\n",
    "    loss_summary = tf.summary.scalar(\"loss_avg\", loss_avg)\n",
    "    sum_op = tf.summary.merge_all()\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    for ep in range(epochs):\n",
    "        train_cost = 0\n",
    "        label_err_rate = 0\n",
    "        batch_feeder = Batch()\n",
    "        n_batches = np.ceil(len(batch_feeder.audio)/batch_feeder.batch_size)\n",
    "        n_batches = int(n_batches)\n",
    "        st = time.time()\n",
    "        for batch in range(n_batches):\n",
    "            src,len_src,labels_src = batch_feeder.get_next_batch()\n",
    "            data_dict = {input_t: src, tgts: labels_src,len_seq:len_src}\n",
    "            batch_cost, _,summ = sess.run([loss_avg, adm_opt,sum_op], data_dict)\n",
    "            train_cost += batch_cost * batch_feeder.batch_size\n",
    "            print(\"Batch cost: {0}, Train cost: {1}\".format(batch_cost,train_cost))\n",
    "            label_err_rate += sess.run(error_rate, feed_dict=data_dict) * batch_feeder.batch_size\n",
    "            print('Label error: {}'.format(label_err_rate))\n",
    "            writer.add_summary(summ,ep*batch_feeder.batch_size+batch)\n",
    "        saver = tf.train.Saver() \n",
    "        saver.save(sess, './speech2txt.ckpt')\n",
    "        decoded_val = sess.run(dec[0], feed_dict=data_dict)\n",
    "        d_decoded_val = tf.sparse_tensor_to_dense(decoded_val, default_value=-1).eval(session=sess)\n",
    "        d_lbl = decoded_val_to_text(labels_src)\n",
    "        cnt = 0\n",
    "        cnt_max = 4\n",
    "        if cnt < cnt_max:\n",
    "            for actual_val, decoded_val in zip(d_lbl, d_decoded_val):\n",
    "                d_str = array2txt(decoded_val)\n",
    "                print('Batch {}'.format(batch))\n",
    "                print('Actual: {}'.format(actual_val))\n",
    "                print('Predicted:  {}'.format(d_str))\n",
    "                cnt += 1\n",
    "        time_taken = time.time() - st\n",
    "        log = 'Epoch {}/{}, training_cost: {:.3f}, error_rate: {:.3f}, time: {:.2f} sec'\n",
    "        print(log.format(ep,epochs,train_cost/len(batch_feeder.audio),\n",
    "                (label_err_rate/len(batch_feeder.audio)), time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B0uQBekOqMe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SpeechRecognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
